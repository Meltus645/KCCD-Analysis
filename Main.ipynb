{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c94bb84-2e8c-4dfb-ab3b-6d5a86bd6f04",
   "metadata": {},
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc154174-2579-455c-b948-2b6a19186bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.session import SparkSession\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb736e0-4f8c-431e-a8f2-2fe6c399c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR =Path(__name__).resolve().parent /'data'\n",
    "SPARK_SESSION =SparkSession.builder.appName(\"KCCD Analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9e6bb-f2ee-44b2-9ed3-24937544a549",
   "metadata": {},
   "source": [
    "**1. Read Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd9fbc76-d9d5-425b-bd47-1c93cb33274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path:str)->tuple:\n",
    "    df =SPARK_SESSION.read.csv(path, inferSchema =True, header =True)\n",
    "    return path.split('_')[3], df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8821ce58-4d09-481c-90d8-a081a4a5ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(DIR =DATA_DIR):\n",
    "    dfs, paths ={}, []\n",
    "    for root, _, files in os.walk(DIR):\n",
    "        for file in files:\n",
    "            path =os.path.join(root, file)\n",
    "            if os.path.exists(path): paths.append(path)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        jobs = [executor.submit(read_csv, path) for path in paths]\n",
    "        for job in jobs:\n",
    "            year, df =job.result()\n",
    "            dfs[year] =df\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "438ca814-c1bf-45f3-a1d1-9bf1ba77ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets =read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5bf92-988e-47e7-b4cb-78f13e4a9de8",
   "metadata": {},
   "source": [
    "**2. Data Exploration and Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3a0a82-892c-4d96-bf88-a87aeb158f9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def explore_dfs(dfs:dict):\n",
    "    NULL_FIELDS, dfc =[], []\n",
    "    title =\"Year\\t\\tColumns\\t\\tRows\\t\\tNull Columns\\t\\tNull Fields\"\n",
    "    print(title)\n",
    "    print(\"==\"*len(title))\n",
    "    for year, df in dfs.items():\n",
    "        cols =df.columns\n",
    "        dfc =dict(df.dtypes)\n",
    "        col_nulls_ct =df.select([functions.sum(functions.col(col).isNull().cast(\"int\")).alias(col) for col in df.columns])\n",
    "        cols_with_nulls = col_nulls_ct.columns\n",
    "        cols_with_nulls =[]\n",
    "        for col in cols_with_nulls:\n",
    "            if col_nulls_ct.select(functions.col(col)).head()[0] >0: cols_with_nulls.append(col)\n",
    "        cols_with_nulls= col_nulls_ct.select(cols_with_nulls)\n",
    "        null_counts_dict = cols_with_nulls.first().asDict()\n",
    "        total_cols =len(cols)\n",
    "        null_fields =sum([val for val in null_counts_dict.values()])\n",
    "        total_rows =df.count()\n",
    "        total_fields =total_rows *total_cols\n",
    "        percantage_nulls =(null_fields/total_fields) *100\n",
    "        print(f\"{year}\\t\\t{total_cols}\\t\\t{total_rows}\\t\\t{len(null_counts_dict)}\\t\\t\\t{null_fields}/{total_fields} - ({percantage_nulls:.2f}%)\")\n",
    "    \n",
    "    print(\"\\nColumns\")\n",
    "    print(\"===\"*len(title))\n",
    "    print(dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cc2f210-c703-4e27-a5fe-fd219196da17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\t\tColumns\t\tRows\t\tNull Columns\t\tNull Fields\n",
      "============================================================================================\n",
      "2009\t\t23\t\t394079\t\t0\t\t\t0/9063817 - (0.00%)\n",
      "2010\t\t23\t\t403470\t\t0\t\t\t0/9279810 - (0.00%)\n",
      "2011\t\t23\t\t379397\t\t0\t\t\t0/8726131 - (0.00%)\n",
      "2012\t\t23\t\t386723\t\t0\t\t\t0/8894629 - (0.00%)\n",
      "2013\t\t23\t\t375453\t\t0\t\t\t0/8635419 - (0.00%)\n",
      "2014\t\t23\t\t365153\t\t0\t\t\t0/8398519 - (0.00%)\n",
      "2015\t\t23\t\t360611\t\t0\t\t\t0/8294053 - (0.00%)\n",
      "2016\t\t23\t\t378577\t\t0\t\t\t0/8707271 - (0.00%)\n",
      "2017\t\t23\t\t357847\t\t0\t\t\t0/8230481 - (0.00%)\n",
      "2018\t\t23\t\t350897\t\t0\t\t\t0/8070631 - (0.00%)\n",
      "2019\t\t23\t\t261352\t\t0\t\t\t0/6011096 - (0.00%)\n",
      "2020\t\t23\t\t254079\t\t0\t\t\t0/5843817 - (0.00%)\n",
      "2021\t\t23\t\t92127\t\t0\t\t\t0/2118921 - (0.00%)\n",
      "2022\t\t23\t\t101848\t\t0\t\t\t0/2342504 - (0.00%)\n",
      "2023\t\t23\t\t88625\t\t0\t\t\t0/2038375 - (0.00%)\n",
      "\n",
      "Columns\n",
      "==========================================================================================================================================\n",
      "{'Report_No': 'string', 'Reported_Date': 'string', 'Reported_Time': 'timestamp', 'From_Date': 'string', 'From_Time': 'timestamp', 'To_Date': 'string', 'To_Time': 'timestamp', 'Offense': 'string', 'IBRS': 'string', 'Description': 'string', 'Beat': 'int', 'Address': 'string', 'City': 'string', 'Zip_Code': 'int', 'Rep_Dist': 'string', 'Area': 'string', 'DVFlag': 'boolean', 'Involvement': 'string', 'Race': 'string', 'Sex': 'string', 'Age': 'int', 'Firearm_Used_Flag': 'boolean', 'Location': 'string'}\n"
     ]
    }
   ],
   "source": [
    "explore_dfs(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1281072-8afc-4aee-9b70-0a103cd688a9",
   "metadata": {},
   "source": [
    "**3. Handling missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6669e0c2-379e-4d40-8182-9036a1618dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1701473-6cbf-4ca8-8f3d-7f76204ecf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dfs:dict):\n",
    "    fill_with_mean =['Age']\n",
    "    fill_with_u =['Sex']\n",
    "    fill_with_unknown =['Description', 'Area', 'Rep_Dist']\n",
    "    for year, df in dfs.items():\n",
    "        df_clean[year] =df.select([*fill_with_unknown, *fill_with_mean, *fill_with_u,'Zip_Code'])\n",
    "        df_clean[year] =df_clean[year].na.fill('Uknown', subset =fill_with_unknown)\n",
    "        df_clean[year] =df_clean[year].na.fill('U', subset =fill_with_u)\n",
    "        for col in fill_with_mean: \n",
    "            df_clean[year] =df_clean[year].withColumn(col, functions.when(df_clean[year][col].isNull(), df_clean[year].select(functions.mean(col)).collect()[0][0]).otherwise(df_clean[year][col]))\n",
    "        top_n =50\n",
    "        zip_code_counts =df_clean[year].groupBy(\"Zip_Code\").count()\n",
    "        sorted_zip_codes =zip_code_counts.orderBy(functions.col(\"count\").desc()).limit(top_n)\n",
    "        df_clean[year] =df_clean[year].filter(functions.col(\"Zip_Code\").isin([row.Zip_Code for row in sorted_zip_codes.collect()]))\n",
    "        df_clean[year] =df_clean[year].na.drop(how ='any')\n",
    "        df_clean[year] =df_clean[year].filter(functions.col('Age') >=5 & functions.col('Age') <=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b025cd1-4ad6-46f6-895f-a441ee455ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataset(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23fbd33-2ccc-404c-b420-77653d8dbed5",
   "metadata": {},
   "source": [
    "**4. Data Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "555748da-20a4-4d89-a473-46e243515a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset(dfs:dict):\n",
    "    for year, df in dfs.items():\n",
    "        df_clean[year] =df_clean[year].withColumn(\"Age\", functions.col(\"Age\").cast(\"int\"))\n",
    "        df_clean[year] =df_clean[year].withColumn(\"Zip_Code\", functions.col(\"Zip_Code\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21f208d1-3cab-431e-880a-53fffac820b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dataset(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f09c0f9-a3bc-4cdb-b316-3b57670a3f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\t\tColumns\t\tRows\t\tNull Columns\t\tNull Fields\n",
      "============================================================================================\n",
      "2009\t\t6\t\t126941\t\t0\t\t\t0/761646 - (0.00%)\n",
      "2010\t\t6\t\t131914\t\t0\t\t\t0/791484 - (0.00%)\n",
      "2011\t\t6\t\t124601\t\t0\t\t\t0/747606 - (0.00%)\n",
      "2012\t\t6\t\t126463\t\t0\t\t\t0/758778 - (0.00%)\n",
      "2013\t\t6\t\t121359\t\t0\t\t\t0/728154 - (0.00%)\n",
      "2014\t\t6\t\t120140\t\t0\t\t\t0/720840 - (0.00%)\n",
      "2015\t\t6\t\t121236\t\t0\t\t\t0/727416 - (0.00%)\n",
      "2016\t\t6\t\t127212\t\t0\t\t\t0/763272 - (0.00%)\n",
      "2017\t\t6\t\t131436\t\t0\t\t\t0/788616 - (0.00%)\n",
      "2018\t\t6\t\t128256\t\t0\t\t\t0/769536 - (0.00%)\n",
      "2019\t\t6\t\t88463\t\t0\t\t\t0/530778 - (0.00%)\n",
      "2020\t\t6\t\t84128\t\t0\t\t\t0/504768 - (0.00%)\n",
      "2021\t\t6\t\t86679\t\t0\t\t\t0/520074 - (0.00%)\n",
      "2022\t\t6\t\t95829\t\t0\t\t\t0/574974 - (0.00%)\n",
      "2023\t\t6\t\t83301\t\t0\t\t\t0/499806 - (0.00%)\n",
      "\n",
      "Columns\n",
      "==========================================================================================================================================\n",
      "{'Description': 'string', 'Area': 'string', 'Rep_Dist': 'string', 'Age': 'int', 'Sex': 'string', 'Zip_Code': 'int'}\n"
     ]
    }
   ],
   "source": [
    "explore_dfs(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ecb8dad-5c68-40d8-a785-8228beaf5de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated, yearly_stats ={}, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "077fdbe8-ed5b-4e9b-922a-e4ee5bb3a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_datasets(dfs:dict):\n",
    "    for year, df in dfs.items():\n",
    "        df_aggregated[year] ={}\n",
    "        for col in df.columns:\n",
    "            df_aggregated[year][col]= df.groupBy(col).agg(functions.count(col).alias(\"Crimes\"))\n",
    "        yearly_stats.append([str(year), df.count()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6acbb532-4b5f-409f-8b61-37253b73ee59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aggregate_datasets(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d90e67e1-e7e3-4970-bd45-3449e99caa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "yearly_crimes_df = pd.DataFrame(yearly_stats, columns=[\"Year\", \"Crimes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f9e620c-24a9-4a49-8f4a-c9ca7db6d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(dfs:dict):\n",
    "    try:\n",
    "        if os.path.exists('out'): shutil.rmtree('out')\n",
    "        else: os.mkdir('out')\n",
    "        yearly_crimes_df.to_csv('out/Yearly.csv', index=False)\n",
    "        for year, df in dfs.items(): \n",
    "            print(f\"Saving {year} dataset\")\n",
    "            for key, rec in df.items(): rec.write.options(header='True', delimiter=',').csv(f\"out/{year}/{key}\")\n",
    "    except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71b1879b-36f9-4c43-a3aa-f49ac04eeb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 2009 dataset\n",
      "Saving 2010 dataset\n",
      "Saving 2011 dataset\n",
      "Saving 2012 dataset\n",
      "Saving 2013 dataset\n",
      "Saving 2014 dataset\n",
      "Saving 2015 dataset\n",
      "Saving 2016 dataset\n",
      "Saving 2017 dataset\n",
      "Saving 2018 dataset\n",
      "Saving 2019 dataset\n",
      "Saving 2020 dataset\n",
      "Saving 2021 dataset\n",
      "Saving 2022 dataset\n",
      "Saving 2023 dataset\n"
     ]
    }
   ],
   "source": [
    "write_csv(df_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6504e9-d919-4597-a326-6ad2716d94a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pyspark",
   "language": "python",
   "name": ".pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
