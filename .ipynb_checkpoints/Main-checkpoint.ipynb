{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c94bb84-2e8c-4dfb-ab3b-6d5a86bd6f04",
   "metadata": {},
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc154174-2579-455c-b948-2b6a19186bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.session import SparkSession\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb736e0-4f8c-431e-a8f2-2fe6c399c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARK_CONTEXT =SparkContext()\n",
    "SPARK_SESSION =SparkSession(SPARK_CONTEXT)\n",
    "DATA_DIR =Path(__name__).resolve().parent /'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9e6bb-f2ee-44b2-9ed3-24937544a549",
   "metadata": {},
   "source": [
    "**1. Read Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd9fbc76-d9d5-425b-bd47-1c93cb33274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path:str)->tuple:\n",
    "    df =SPARK_SESSION.read.csv(path, inferSchema =True, header =True)\n",
    "    return path.split('_')[3], df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8821ce58-4d09-481c-90d8-a081a4a5ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(DIR =DATA_DIR):\n",
    "    dfs, paths ={}, []\n",
    "    for root, _, files in os.walk(DIR):\n",
    "        for file in files:\n",
    "            path =os.path.join(root, file)\n",
    "            if os.path.exists(path): paths.append(path)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        jobs = [executor.submit(read_csv, path) for path in paths]\n",
    "        for job in jobs:\n",
    "            year, df =job.result()\n",
    "            dfs[year] =df\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "438ca814-c1bf-45f3-a1d1-9bf1ba77ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets =read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5bf92-988e-47e7-b4cb-78f13e4a9de8",
   "metadata": {},
   "source": [
    "**2. Data Exploration and Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fc3a0a82-892c-4d96-bf88-a87aeb158f9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def explore_dfs(dfs:dict):\n",
    "    NULL_FIELDS, dfc =[], []\n",
    "    title =\"Year\\t\\tColumns\\t\\tRows\\t\\tNull Columns\\t\\tNull Fields\"\n",
    "    print(title)\n",
    "    print(\"==\"*len(title))\n",
    "    for year, df in dfs.items():\n",
    "        cols =df.columns\n",
    "        dfc =dict(df.dtypes)\n",
    "        col_nulls_ct =df.select([functions.sum(functions.col(col).isNull().cast(\"int\")).alias(col) for col in df.columns])\n",
    "        cols_with_nulls = col_nulls_ct.columns\n",
    "        cols_with_nulls = [col for col in cols_with_nulls if col_nulls_ct.select(functions.col(col)).head()[0] > 0]\n",
    "        cols_with_nulls= col_nulls_ct.select(cols_with_nulls)\n",
    "        null_counts_dict = cols_with_nulls.first().asDict()\n",
    "        total_cols =len(cols)\n",
    "        null_fields =sum([val for val in null_counts_dict.values()])\n",
    "        total_fields =df.count() * total_cols\n",
    "        percantage_nulls =(null_fields/total_fields) *100\n",
    "        print(f\"{year}\\t\\t{total_cols}\\t\\t{total_fields}\\t\\t{len(null_counts_dict)}\\t\\t\\t{null_fields}/{total_fields} - ({percantage_nulls:.2f}%)\")\n",
    "    \n",
    "    print(\"\\nColumns\")\n",
    "    print(\"===\"*len(title))\n",
    "    print(dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0cc2f210-c703-4e27-a5fe-fd219196da17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\t\tColumns\t\tRows\t\tNull Columns\t\tNull Fields\n",
      "============================================================================================\n",
      "2009\t\t23\t\t9063817\t\t22\t\t\t5720513/9063817 - (63.11%)\n",
      "2010\t\t23\t\t9279810\t\t22\t\t\t5857853/9279810 - (63.12%)\n",
      "2011\t\t23\t\t8726131\t\t22\t\t\t5510868/8726131 - (63.15%)\n",
      "2012\t\t23\t\t8894629\t\t22\t\t\t5622606/8894629 - (63.21%)\n",
      "2013\t\t23\t\t8635419\t\t21\t\t\t5746671/8635419 - (66.55%)\n",
      "2014\t\t23\t\t8398519\t\t22\t\t\t5412128/8398519 - (64.44%)\n",
      "2015\t\t23\t\t8294053\t\t22\t\t\t5371371/8294053 - (64.76%)\n",
      "2016\t\t23\t\t8707271\t\t22\t\t\t5672925/8707271 - (65.15%)\n",
      "2017\t\t23\t\t8230481\t\t22\t\t\t5139314/8230481 - (62.44%)\n",
      "2018\t\t23\t\t8070631\t\t22\t\t\t5049805/8070631 - (62.57%)\n",
      "2019\t\t23\t\t6011096\t\t22\t\t\t3702927/6011096 - (61.60%)\n",
      "2020\t\t23\t\t5843817\t\t22\t\t\t3645348/5843817 - (62.38%)\n",
      "2021\t\t23\t\t2118921\t\t15\t\t\t226414/2118921 - (10.69%)\n",
      "2022\t\t23\t\t2342504\t\t9\t\t\t166395/2342504 - (7.10%)\n",
      "2023\t\t23\t\t2038375\t\t13\t\t\t199552/2038375 - (9.79%)\n",
      "\n",
      "Columns\n",
      "==========================================================================================================================================\n",
      "{'Report_No': 'string', 'Reported_Date': 'string', 'Reported_Time': 'timestamp', 'From_Date': 'string', 'From_Time': 'timestamp', 'To_Date': 'string', 'To_Time': 'timestamp', 'Offense': 'string', 'IBRS': 'string', 'Description': 'string', 'Beat': 'int', 'Address': 'string', 'City': 'string', 'Zip_Code': 'int', 'Rep_Dist': 'string', 'Area': 'string', 'DVFlag': 'boolean', 'Involvement': 'string', 'Race': 'string', 'Sex': 'string', 'Age': 'int', 'Firearm_Used_Flag': 'boolean', 'Location': 'string'}\n"
     ]
    }
   ],
   "source": [
    "explore_dfs(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1281072-8afc-4aee-9b70-0a103cd688a9",
   "metadata": {},
   "source": [
    "**3. Handling missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6669e0c2-379e-4d40-8182-9036a1618dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c1701473-6cbf-4ca8-8f3d-7f76204ecf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dfs:dict):\n",
    "    fill_with_mean =['Age']\n",
    "    fill_with_o =['Race', 'Sex', 'Firearm_Used_Flag']\n",
    "    fill_with_others =['City', 'Involvement' ,'Description', 'Area']\n",
    "    for year, df in dfs.items(): \n",
    "        df_clean[year] =df.select([*fill_with_others, *fill_with_mean, *fill_with_o])\n",
    "        df_clean[year] =df_clean[year].na.fill('Other', subset =fill_with_others)\n",
    "        df_clean[year] =df_clean[year].withColumn('Firearm_Used_Flag',\n",
    "            functions.when(\n",
    "            (functions.lower(functions.col(\"Firearm_Used_Flag\")) == \"f\") | \n",
    "            (functions.lower(functions.col(\"Firearm_Used_Flag\")) == \"false\") | \n",
    "            (functions.lower(functions.col(\"Firearm_Used_Flag\")) == \"n\") | \n",
    "            (functions.lower(functions.col(\"Firearm_Used_Flag\")) == \"no\"), False)\n",
    "            .when(\n",
    "            (functions.lower(functions.col(\"Firearm_Used_Flag\")) == \"t\") | \n",
    "            (functions.lower(functions.col(\"Firearm_Used_Flag\")) == \"true\") | \n",
    "            (functions.lower(functions.col(\"Firearm_Used_Flag\")) == \"y\") | \n",
    "            (functions.lower(functions.col(\"Firearm_Used_Flag\")) == \"yes\"), True)\n",
    "            .otherwise(False)                                     \n",
    "        )\n",
    "        df_clean[year] =df_clean[year].withColumn('Sex',\n",
    "            functions.when(\n",
    "                (functions.lower(functions.col(\"Sex\")) =='f') |\n",
    "                (functions.lower(functions.col(\"Sex\")) =='female'), 'Female')\n",
    "            .when(\n",
    "                (functions.lower(functions.col(\"Sex\")) == 'm')|\n",
    "                (functions.lower(functions.col(\"Sex\")) == 'male'), 'Male')\n",
    "            .otherwise('Other')                                     \n",
    "        )\n",
    "\n",
    "        df_clean[year] =df_clean[year].withColumn('Race',\n",
    "            functions.when( (functions.lower(functions.col(\"Race\")) =='w'), 'White')\n",
    "            .when((functions.lower(functions.col(\"Race\")) == 'b'), 'Black')\n",
    "            .otherwise('Other')                                     \n",
    "        )\n",
    "        \n",
    "        for col in fill_with_mean: \n",
    "            df_clean[year] =df_clean[year].withColumn(col, functions.when(df_clean[year][col].isNull(), df_clean[year].select(functions.mean(col)).collect()[0][0]).otherwise(df_clean[year][col]))\n",
    "        df_clean[year] =df_clean[year].na.drop(how ='any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0b025cd1-4ad6-46f6-895f-a441ee455ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataset(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23fbd33-2ccc-404c-b420-77653d8dbed5",
   "metadata": {},
   "source": [
    "**4. Data Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "555748da-20a4-4d89-a473-46e243515a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset(dfs:dict):\n",
    "    for year, df in dfs.items():\n",
    "        df_clean[year] =df_clean[year].withColumn(\"Age\", functions.col(\"Age\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "21f208d1-3cab-431e-880a-53fffac820b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dataset(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2f09c0f9-a3bc-4cdb-b316-3b57670a3f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\t\tColumns\t\tRows\t\tNull Columns\t\tNull Fields\n",
      "============================================================================================\n",
      "2009\t\t8\t\t3152632\t\t0\t\t\t0/3152632 - (0.00%)\n",
      "2010\t\t8\t\t3227760\t\t0\t\t\t0/3227760 - (0.00%)\n",
      "2011\t\t8\t\t3035176\t\t0\t\t\t0/3035176 - (0.00%)\n",
      "2012\t\t8\t\t3093784\t\t0\t\t\t0/3093784 - (0.00%)\n",
      "2013\t\t8\t\t3003624\t\t0\t\t\t0/3003624 - (0.00%)\n",
      "2014\t\t8\t\t2921224\t\t0\t\t\t0/2921224 - (0.00%)\n",
      "2015\t\t8\t\t2884888\t\t0\t\t\t0/2884888 - (0.00%)\n",
      "2016\t\t8\t\t3028616\t\t0\t\t\t0/3028616 - (0.00%)\n",
      "2017\t\t8\t\t2862776\t\t0\t\t\t0/2862776 - (0.00%)\n",
      "2018\t\t8\t\t2807176\t\t0\t\t\t0/2807176 - (0.00%)\n",
      "2019\t\t8\t\t2090816\t\t0\t\t\t0/2090816 - (0.00%)\n",
      "2020\t\t8\t\t2032632\t\t0\t\t\t0/2032632 - (0.00%)\n",
      "2021\t\t8\t\t737016\t\t0\t\t\t0/737016 - (0.00%)\n",
      "2022\t\t8\t\t814784\t\t0\t\t\t0/814784 - (0.00%)\n",
      "2023\t\t8\t\t709000\t\t0\t\t\t0/709000 - (0.00%)\n",
      "\n",
      "Columns\n",
      "==========================================================================================================================================\n",
      "{'City': 'string', 'Involvement': 'string', 'Description': 'string', 'Area': 'string', 'Age': 'int', 'Race': 'string', 'Sex': 'string', 'Firearm_Used_Flag': 'boolean'}\n"
     ]
    }
   ],
   "source": [
    "explore_dfs(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9f9e620c-24a9-4a49-8f4a-c9ca7db6d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(dfs:dict):\n",
    "    try:\n",
    "        if os.path.exists('out'): shutil.rmtree('out')\n",
    "        else: os.mkdir('out')\n",
    "        for year, df in dfs.items(): \n",
    "            print(f\"Saving {year} dataset\")\n",
    "            df.write.options(header='True', delimiter=',').csv(f\"out/{year}\")\n",
    "    except Exception: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "71b1879b-36f9-4c43-a3aa-f49ac04eeb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 2009 dataset\n",
      "Saving 2010 dataset\n",
      "Saving 2011 dataset\n",
      "Saving 2012 dataset\n",
      "Saving 2013 dataset\n",
      "Saving 2014 dataset\n",
      "Saving 2015 dataset\n",
      "Saving 2016 dataset\n",
      "Saving 2017 dataset\n",
      "Saving 2018 dataset\n",
      "Saving 2019 dataset\n",
      "Saving 2020 dataset\n",
      "Saving 2021 dataset\n",
      "Saving 2022 dataset\n",
      "Saving 2023 dataset\n"
     ]
    }
   ],
   "source": [
    "write_csv(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6504e9-d919-4597-a326-6ad2716d94a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pyspark",
   "language": "python",
   "name": ".pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
